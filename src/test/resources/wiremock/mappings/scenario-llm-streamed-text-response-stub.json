{
  "scenarioName": "LLM Tool Call Then Text Response",
  "requiredScenarioState": "TextResponse",
  "request": {
    "method": "POST",
    "urlPattern": "/openai/deployments/stubbed-scenario/chat/completions.*"
  },
  "response": {
    "status": 200,
    "headers": {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      "Connection": "keep-alive"
    },
    "bodyFileName": "llm_streamed_text_response.txt"
  }
}
